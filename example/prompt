# Documentation

https://raw.githubusercontent.com/openai/openai-python/main/README.md

# Task

Implement an AI assistant in Python using the GPT-4o model. The assistant should accept a JSON schema that defines the structure of the target output. The assistant's primary task is to dynamically generate and ask questions based on this schema, utilizing the GPT-4o model to ensure a natural and coherent conversational flow. As the user provides responses, the assistant should use GPT-4o to analyze the unstructured input, extract relevant information, and incrementally assemble the final JSON document according to the schema.
Please note that your knowledge of OpenAI client integration may be outdated. Always refer to the latest code samples for up-to-date references.

# Files

- `main.py`: initializes the agent and imports all necesairy functions and modules.
- `chat_completion.py`: Receives a prompt and returns a chat completion from the GPT-4o model. Every LLM function should use this function. Pay attention to the OpenAI client integration; use the most up-to-date code provided in the documentation. Utilize the with options method to specify three retries. Always consult the documentation to ensure the generated code is current.
- `analyze_schema.py`: Accepts a JSON schema and validates its structure according to the JSON Schema standard, ensuring that the schema itself is valid.
- `generate_question.py`: Receives a field from the schema file and generates a question based on it using the GPT-4o model. The received field is a key from the schema file, comprising the property name and the property type.
- `process_user_answer.py`: Receives a user's response (string) to a generated question and determines if it is a valid answer. It returns an inferred answer. The function uses the GPT-4o model to analyze the user's response and extract its meaning, returning only the value necessary for setting the JSON property. Use this prompt to instruct the LLM: "Extract the key alphanumerical value or entity from the user's response that directly answers the question. Return this value in its most straightforward form."
- `update_intermediate_result.py`: Receives a schema key (string) and the inferred user answer, then updates an in-memory JSON document.
- `terminate_and_respond.py`: Once all answers are received, the script should respond to the user with the generated JSON document and terminate itself.
- `schema.json`: Example schema file containing the following required fields: full name, age, and email.

# Code Guidelines

- Avoid circular imports.
- Do not limit the token length of the completion.
- Ensure all necessary imports for required libraries or modules are included at the beginning of the file. Review the code to verify that nothing is missing.
- Use the GPT-4o model for all functions.
- Ensure you are using the latest version of the OpenAI client.
- The OpenAI API key is provided as an environment variable (OPENAI_API_KEY).
- The JSON schema file is provided as a configuration file (schema.json).
- Place all results in the `src` folder.
- Do not generate any code comments.
- Ensure the import statements do NOT include the src namespace.

# Functionality

- The agent should proceed to the next question after receiving an answer.
- The agent should terminate its task once all questions are answered.
